# Spike Transformer

A from-scratch implementation of Spike-driven Transformers using only NumPy.

## Papers Implemented

- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762) - Original Transformer
- [Spike-driven Transformer](https://arxiv.org/pdf/2307.01694) - First spike-based transformer
- [Spike-driven Transformer V2](https://arxiv.org/pdf/2404.03663) - Improved architecture
- [Scaling Spike-driven Transformer](https://arxiv.org/pdf/2411.16061v1) - Scaling techniques

## Objective:

- Create an impressive, accurate demo of Spike Transformers given the following constraints.

## Contraints:

- Keep everything simple and easy to understand
- No external libraries except numpy.
- Keep the implementation below 1000 lines
- Keep the training data less tha 1000 examples

## Getting Started

```bash
python3 SpikeTransformer
```

## High Score

Epoch 90: Loss = 0.9946, Accuracy = 65.3%, Avg Spike Rate = 0.376
